{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "while pathlib.Path(\".\").absolute().name != \"aerial-disentangled-representations\":\n",
    "    os.chdir(\"..\")"
   ],
   "id": "804e85cc517bbe38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "DEVICE = \"mps\"",
   "id": "ab45d1dded6a2e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.environ[\"NO_ALBUMENTATIONS_UPDATE\"] = \"1\"\n",
    "from disentangled_representations.src.data_processing.aerial_dataset_instances import aerial_datasets_mapping, \\\n",
    "    Hi_UCD_Dataset, A\n",
    "\n",
    "Hi_UCD_test_dataset = aerial_datasets_mapping[\"Hi_UCD_Dataset_test\"]\n",
    "Hi_UCD_test_dataset_visuals = Hi_UCD_Dataset(split=\"test\", read_color=True,\n",
    "                                             shared_transform=A.Compose([], additional_targets={}),\n",
    "                                             unique_transform=A.Compose([]))"
   ],
   "id": "f2208de75d57d96a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model loading\n",
    "\n",
    "Requires model's checkpoint."
   ],
   "id": "6a2a94bde2c1d438"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pathlib\n",
    "from loguru import logger\n",
    "\n",
    "ckpt_dir = pathlib.Path(\"tb_logs\") / \"disent_rep\" / \"Deterministic projector | dim(z) = 128\" / \"checkpoints\""
   ],
   "id": "ce212db0108cecd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from disentangled_representations.src.training_procedure import LitKapellmeister, LossWeights\n",
    "from disentangled_representations.src.models.projectors import SimpleDeterministicProjector, SimpleVariationalProjector\n",
    "from disentangled_representations.src.models.image_encoders import EfficientNetB0\n",
    "\n",
    "\n",
    "def load_models_by_checkpoint_dir_path(ckpt_dir: pathlib.Path, out_dim: int, variational: bool):\n",
    "    assert ckpt_dir.is_dir()\n",
    "\n",
    "    _ckpt_paths = list(ckpt_dir.glob(\"*.ckpt\"))\n",
    "    if len(_ckpt_paths) != 1:\n",
    "        logger.warning(f\"{_ckpt_paths=}\")\n",
    "\n",
    "    ckpt_path = _ckpt_paths[0]\n",
    "\n",
    "    encoder = EfficientNetB0(in_channels=1)\n",
    "    embedding_dim = int(encoder.feature_dim)\n",
    "\n",
    "    if variational:\n",
    "        projector = SimpleVariationalProjector(\n",
    "            input_dimensionality=embedding_dim,\n",
    "            hidden_features=[512],\n",
    "            latent_dimensionality=out_dim // 2\n",
    "        )\n",
    "    else:\n",
    "        projector = SimpleDeterministicProjector(\n",
    "            input_dimensionality=embedding_dim,\n",
    "            hidden_features=[512],\n",
    "            output_dimensionality=out_dim\n",
    "        )\n",
    "\n",
    "    loss_weights = LossWeights(w_NTXent=1.0, w_KL=0.5)\n",
    "\n",
    "    model = LitKapellmeister.load_from_checkpoint(\n",
    "        checkpoint_path=ckpt_path,\n",
    "        image_encoder=encoder,\n",
    "        projector=projector,\n",
    "        loss_weights=loss_weights,\n",
    "        map_location=DEVICE,\n",
    "        strict=True\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "deterministic_lit_kapellmeister = load_models_by_checkpoint_dir_path(ckpt_dir, out_dim=128, variational=False)\n",
    "encoder_det = deterministic_lit_kapellmeister.image_encoder\n",
    "projector_det = deterministic_lit_kapellmeister.projector"
   ],
   "id": "b5cf5b17e89105e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def compute_all_projected_embeddings(dataset, lit_kapellmeister: LitKapellmeister, dim: int):\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=8,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    Z_A = np.empty((len(loader.dataset), dim), dtype=np.float32)\n",
    "    Z_B = Z_A.copy()\n",
    "\n",
    "    idx = 0\n",
    "    device = \"mps\"\n",
    "\n",
    "    project: bool = not lit_kapellmeister.kapellmeister.is_projector_variational\n",
    "    logger.info(f\"{project=}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for A, B in tqdm(loader, desc=\"Computing embeddings\", unit=\"batch\"):\n",
    "            bsz = A.size(0)\n",
    "\n",
    "            A = A.to(device)\n",
    "            B = B.to(device)\n",
    "\n",
    "            zA = lit_kapellmeister(A)\n",
    "            zB = lit_kapellmeister(B)\n",
    "\n",
    "            if project:\n",
    "                # NOTE: a variational embedding should not be projected.\n",
    "                zA = F.normalize(zA, dim=1)\n",
    "                zB = F.normalize(zB, dim=1)\n",
    "\n",
    "            Z_A[idx:idx + bsz] = zA.cpu().numpy()\n",
    "            Z_B[idx:idx + bsz] = zB.cpu().numpy()\n",
    "\n",
    "            idx += bsz\n",
    "    return Z_A, Z_B\n",
    "\n",
    "\n",
    "Z_A_det, Z_B_det = compute_all_projected_embeddings(Hi_UCD_test_dataset, deterministic_lit_kapellmeister, dim=128)"
   ],
   "id": "41388ee9632d12ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# NOTE: full similarities matrix is computed once for brute force nearest neighbour search to avoid performance degradation on the metrics.\n",
    "similarities_det = Z_A_det @ Z_B_det.T"
   ],
   "id": "4214f7eafcae9808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retrieval performance assessment",
   "id": "f663c15217cb79d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evaluate_retrieval_metrics(\n",
    "        similarities,\n",
    "        correct_indices,\n",
    "        ks_map=[1, 5, 10, 20, 50],\n",
    "        max_cmc_k=50,\n",
    "        font_size=24,\n",
    "        save_path=None\n",
    "):\n",
    "    sims = np.asarray(similarities)\n",
    "    correct_idx = np.asarray(correct_indices, dtype=int)\n",
    "    Q, N = sims.shape\n",
    "    assert correct_idx.shape[0] == Q, \"correct_indices must have length `Q`\"\n",
    "\n",
    "    true_sim = sims[np.arange(Q), correct_idx]\n",
    "    rank_positions = 1 + np.sum(sims > true_sim[:, None], axis=1)\n",
    "\n",
    "    rank1_acc = np.mean(rank_positions == 1)\n",
    "    print(f\"Rank-1 accuracy: {rank1_acc * 100:.2f}%\")\n",
    "\n",
    "    cmc_ks = np.arange(1, max_cmc_k + 1)\n",
    "    cmc = np.mean(rank_positions[:, None] <= cmc_ks[None, :], axis=0)\n",
    "\n",
    "    ks = np.array(ks_map)\n",
    "    precisions = np.where(\n",
    "        rank_positions[:, None] <= ks[None, :],\n",
    "        1.0 / rank_positions[:, None],\n",
    "        0.0\n",
    "    )\n",
    "    map_at_k = np.mean(precisions, axis=0)\n",
    "\n",
    "    # ——— PLOTTING ———\n",
    "    plt.rcParams.update({\n",
    "        \"font.size\": font_size,\n",
    "        \"axes.titlesize\": font_size,\n",
    "        \"axes.labelsize\": font_size,\n",
    "        \"xtick.labelsize\": font_size * 0.8,\n",
    "        \"ytick.labelsize\": font_size * 0.8,\n",
    "        \"legend.fontsize\": font_size * 0.8,\n",
    "    })\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.plot(cmc_ks, cmc, lw=2)\n",
    "    ax.set_xlabel(\"k\", fontsize=font_size)\n",
    "    ax.set_ylabel(\"CMC(k) / Recall@k\", fontsize=font_size)\n",
    "    ax.set_title(\"CMC Curve (Recall@k)\", fontsize=font_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=font_size * 0.8)\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.plot(ks, map_at_k, marker='o', lw=2)\n",
    "    ax.set_xlabel(\"k\", fontsize=font_size)\n",
    "    ax.set_ylabel(\"mAP@k\", fontsize=font_size)\n",
    "    ax.set_title(\"Mean Average Precision @ K\", fontsize=font_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=font_size * 0.8)\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, format='pdf')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'rank1_acc': rank1_acc,\n",
    "        'cmc_ks': cmc_ks,\n",
    "        'cmc': cmc,\n",
    "        'ks_map': ks,\n",
    "        'map_at_k': map_at_k,\n",
    "        'rank_positions': rank_positions\n",
    "    }"
   ],
   "id": "53451c03c8899a1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_ = evaluate_retrieval_metrics(similarities_det, np.arange(similarities_det.shape[0]), ks_map=[1, 2, 3, 5, 10, 15, 20, 30, 50], save_path=None)",
   "id": "c3ca3c2810676aea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Retrieval visualizations\n",
   "id": "89f3e5f8c8582ac3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualize_retrieval_batch(\n",
    "        query_imgs,\n",
    "        retrieved_imgs,\n",
    "        k=5,\n",
    "        figsize_per_query=(2.5, 2.5),\n",
    "        font_size=14,\n",
    "        save_path=None\n",
    "):\n",
    "    n = len(query_imgs)\n",
    "    cols = k + 1\n",
    "    column_titles = [\"Query\"] + [f\"Rank {i + 1}\" for i in range(k)]\n",
    "    col_colors = [\"#e0f7fa\"] + [\n",
    "        \"#f5f5f5\" if (j % 2) == 0 else \"#ffffff\"\n",
    "        for j in range(1, cols)\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        n + 1,\n",
    "        cols,\n",
    "        figsize=(figsize_per_query[0] * cols, figsize_per_query[1] * (n + 1)),\n",
    "        dpi=200\n",
    "    )\n",
    "\n",
    "    if n == 1:\n",
    "        axes = axes[np.newaxis, :]\n",
    "\n",
    "    for j, title in enumerate(column_titles):\n",
    "        ax = axes[0, j]\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_facecolor(col_colors[j])\n",
    "        ax.text(\n",
    "            0.5, 0.5, title,\n",
    "            ha=\"center\", va=\"center\",\n",
    "            fontsize=font_size,\n",
    "            weight=\"bold\"\n",
    "        )\n",
    "\n",
    "    for i in range(n):\n",
    "        ax = axes[i + 1, 0]\n",
    "        ax.imshow(query_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_facecolor(col_colors[0])\n",
    "\n",
    "        for j in range(k):\n",
    "            ax = axes[i + 1, j + 1]\n",
    "            ax.imshow(retrieved_imgs[i][j])\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_facecolor(col_colors[j + 1])\n",
    "\n",
    "    plt.tight_layout(pad=1.0)\n",
    "\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ],
   "id": "c2ae939f29b743d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_retrieved_images_by_indices(similarities, indices, k: int):\n",
    "    \"\"\"\n",
    "    Returns query images and top-k retrieved images.\n",
    "    \"\"\"\n",
    "    queries_vis = []\n",
    "    for i in indices:\n",
    "        vis_img = Hi_UCD_test_dataset_visuals[i][0]\n",
    "        queries_vis.append(vis_img)\n",
    "\n",
    "    similar_subset = similarities[indices, :]\n",
    "    indices_matrix = np.argsort(-similar_subset, axis=1)[:, :k]\n",
    "    print(f\"Correct: {indices_matrix[:, 0] == np.array(indices)}\")\n",
    "\n",
    "    retrieved_images = []\n",
    "    for row in indices_matrix:\n",
    "        retrieved_images.append([Hi_UCD_test_dataset_visuals[j][1] for j in row])\n",
    "\n",
    "    return queries_vis, retrieved_images\n"
   ],
   "id": "2553e86f32d66fa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "indices_correct = [0, 11, 20, 266, 320, 323]\n",
    "indices_correct_2 = [325, 462, 463, 470, 472, 502]\n",
    "indices_incorrect = [5, 6,  8, 10, 12, 52]\n",
    "random_indices_all = [1557, 1336, 1324, 1590, 1286, 1868, 1907, 1832, 1190, 1613, 1439, 1773]\n",
    "random_indices_1 = random_indices_all[:6]\n",
    "random_indices_2 = random_indices_all[6:]\n",
    "\n",
    "k = 3"
   ],
   "id": "97712082fc2202c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_retrieval_batch(*get_retrieved_images_by_indices(similarities_det, indices_correct, k=k), k=k, save_path=None)",
   "id": "dcbacc10888c491f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_retrieval_batch(*get_retrieved_images_by_indices(similarities_det, indices_correct_2, k=k), k=k, save_path=None)",
   "id": "b75fe2720a3c9bc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_retrieval_batch(*get_retrieved_images_by_indices(similarities_det, indices_incorrect, k=k), k=k, save_path=None)",
   "id": "2a1d09d583a934fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_retrieval_batch(*get_retrieved_images_by_indices(similarities_det, random_indices_1, k=k), k=k, save_path=None)",
   "id": "7dd70d57e920a20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_retrieval_batch(*get_retrieved_images_by_indices(similarities_det, random_indices_2, k=k), k=k, save_path=None)",
   "id": "b3ab59e9b891ef05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Variational",
   "id": "ca58ac1cd7efef9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ckpt_dir_path = pathlib.Path(\"tb_logs\") / \"disent_rep\" / \"Variational projector | dim(z) = 128\" / \"checkpoints\"\n",
    "\n",
    "# NOTE: the MLP's output dimension is 256 because it returns 128 parameters for the Gaussian mean and 128 parameters for its (log-)variance.\n",
    "variational_lit_kapellmeister = load_models_by_checkpoint_dir_path(ckpt_dir_path, out_dim=256, variational=True)\n",
    "encoder_var = variational_lit_kapellmeister.image_encoder\n",
    "projector_var = variational_lit_kapellmeister.projector"
   ],
   "id": "809691205195afce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Z_A_var, Z_B_var = compute_all_projected_embeddings(Hi_UCD_test_dataset, variational_lit_kapellmeister, dim=256)",
   "id": "8c4ae9406054afb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from disentangled_representations.src.models.abstract_models import VariationalProjector\n",
    "\n",
    "mu_A, log_variance_A = VariationalProjector.multivariate_params_from_vector(torch.from_numpy(Z_A_var))\n",
    "mu_B, log_variance_B = VariationalProjector.multivariate_params_from_vector(torch.from_numpy(Z_B_var))"
   ],
   "id": "d7d7f3f7bc7a9c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# NOTE: Log-root generalized variance.\n",
    "log_det_np = (1 / 128) * log_variance_A.sum(dim=1).detach().cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.hist(log_det_np, bins=30, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel(\"Avg. log det Σ\", fontsize=20)\n",
    "ax.set_ylabel(\"Count\", fontsize=20)\n",
    "ax.tick_params(labelsize=18)\n",
    "\n",
    "ax.grid(True)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"generalized_variance\", format='pdf')\n",
    "plt.show()"
   ],
   "id": "a6e2c57bec947d5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "similarities_var = (mu_A / mu_A.norm(dim=1, keepdim=True)) @ (mu_B / mu_B.norm(dim=1, keepdim=True)).T",
   "id": "791c5367ac206e48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_ = evaluate_retrieval_metrics(similarities_var, np.arange(similarities_var.shape[0]), ks_map=[1, 2, 3, 5, 10, 15, 20, 30, 50], save_path=None)",
   "id": "8bdfd165e420b5d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def most_certain_indices(values, quantile=0.2):\n",
    "    thresh = np.quantile(values, quantile)\n",
    "    idx = np.where(values <= thresh)[0]\n",
    "    return idx"
   ],
   "id": "68c3bb74623ef05c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Metrics on 50% of most certain queries:",
   "id": "19f1ac6dbd19bd0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "certain_indices = most_certain_indices(log_det_np, 0.50)\n",
    "_ = evaluate_retrieval_metrics(similarities_var[certain_indices], np.arange(similarities_var.shape[0])[certain_indices],\n",
    "                               ks_map=[1, 2, 3, 5, 10, 15, 20, 30, 50], save_path=\"visuals/retrieval_metrics_V_50p.pdf\")"
   ],
   "id": "232b2ae90a85bdb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Metrics on 20% of the most certain queries:",
   "id": "193d97c9c9e21f20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "certain_indices = most_certain_indices(log_det_np, 0.20)\n",
    "_ = evaluate_retrieval_metrics(similarities_var[certain_indices], np.arange(similarities_var.shape[0])[certain_indices],\n",
    "                               ks_map=[1, 2, 3, 5, 10, 15, 20, 30, 50], save_path=\"visuals/retrieval_metrics_V_20p.pdf\")"
   ],
   "id": "14c0ff4a997232b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Checking the performance of most certain queries predicted by variational projector and applying them on the deterministic approach to show that predicted generalized variance is meaningful.\n",
   "id": "2dba29838a4c6f79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "certain_indices = most_certain_indices(log_det_np, 0.50)\n",
    "_ = evaluate_retrieval_metrics(similarities_det[certain_indices], np.arange(similarities_det.shape[0])[certain_indices],\n",
    "                               ks_map=[1, 2, 3, 5, 10, 15, 20, 30, 50], save_path=None)"
   ],
   "id": "2468b91d5ecfa0d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Variational retrieval examples\n",
   "id": "6b5d895df6b91b34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Some of the image examples used for the deterministic approach:",
   "id": "5fb8b8c11c2af8a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "indices = [0, 11, 20, 266, 320, 323, 325, 462]\n",
    "visualize_retrieval_batch(*get_retrieved_images_by_indices(similarities_var, indices, k=k), k=k, save_path=None)"
   ],
   "id": "44d08fbf9dc6ee18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Checking the performance on more uncertain images. One can see that most images include less detail and are indeed hard to accurately find.",
   "id": "1efeefeff1296985"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "uncertain_indices = np.argsort(log_det_np)[-1005:-995]\n",
    "visualize_retrieval_batch(*get_retrieved_images_by_indices(similarities_var, uncertain_indices, k=k), k=k, save_path=None)"
   ],
   "id": "328fc840c79f982e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
